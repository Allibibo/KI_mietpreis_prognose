{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Lade die Daten\n",
    "def load_data(file_name):\n",
    "    with open(file_name, 'r', encoding='utf-8') as file:\n",
    "        loaded_data = json.load(file)\n",
    "    return loaded_data\n",
    "\n",
    "# Sonderzeichen behandeln\n",
    "def handle_special_characters(value):\n",
    "    if isinstance(value, str):  # Überprüfen, ob der Wert ein String ist\n",
    "        # Umlaute umwandeln\n",
    "        value = value.replace(\"ß\", \"ss\")\n",
    "        value = value.replace(\"ä\", \"ae\")\n",
    "        value = value.replace(\"Ä\", \"Ae\")\n",
    "        value = value.replace(\"Ü\", \"Ue\")\n",
    "        value = value.replace(\"ü\", \"ue\")\n",
    "        value = value.replace(\"ö\", \"oe\")\n",
    "    return value\n",
    "\n",
    "# Sonderzeichen in den geladenen Daten ersetzen\n",
    "def handle_special_chars_in_data(loaded_data):\n",
    "    decoded_data = []\n",
    "    for dictionary in loaded_data:\n",
    "        new_dict = {}\n",
    "        for key, value in dictionary.items():\n",
    "            new_dict[key] = handle_special_characters(value)\n",
    "        decoded_data.append(new_dict)\n",
    "    return decoded_data\n",
    "\n",
    "# Speichern der endgültigen Daten in eine JSON-Datei\n",
    "def save_to_json(data, output_filename):\n",
    "    with open(output_filename, 'w', encoding='utf-8') as file:\n",
    "        json.dump(data, file, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Daten splitten\n",
    "def handle_datasplit(loaded_data):\n",
    "    splitted_data = []\n",
    "    for data in loaded_data:\n",
    "        new_dict = {}\n",
    "        for key, value in data.items():\n",
    "            new_dict[key] = change_values_to_zero_one(key, value)\n",
    "        splitted_data.append(new_dict)\n",
    "    return splitted_data\n",
    "\n",
    "# Daten in Integer 0,1 umwandeln\n",
    "def change_values_to_zero_one(key, value):\n",
    "    if isinstance(value, bool): # Überprüfen ob der Wert Boolean ist\n",
    "        value = int(value)\n",
    "    return value\n",
    "\n",
    "# Daten transformieren\n",
    "def splitdata(loaded_data, attributeList):\n",
    "    attribute_Map =  OrderedDict()  # Map mit gewählten Attributen aufbauen \n",
    "    for attribute in attributeList: \n",
    "        attribute_Map[attribute] = []  \n",
    "    for eintrag in loaded_data: # Map mit values füllen\n",
    "        for attribute in attributeList:\n",
    "            value = attribute_Map[attribute]\n",
    "            if str(eintrag[attribute]) not in value: # Überprüfen auf doppelte Werte\n",
    "                value.append(eintrag[attribute])\n",
    "            attribute_Map[attribute] = value\n",
    "    for eintrag in loaded_data:  \n",
    "        for key in attribute_Map:\n",
    "            for value in attribute_Map[key]:\n",
    "                eintrag[key + ' ' + str(value)] = 0 # Inital auf Null setzen\n",
    "            eintrag[key + ' ' + str(eintrag[key])] = 1\n",
    "            eintrag.pop(key)    \n",
    "    return loaded_data  \n",
    "\n",
    "# Attribute entfernen\n",
    "def pop_Attribute(loaded_data, attributeList):\n",
    "    for eintrag in loaded_data:\n",
    "        for attribute in attributeList:\n",
    "            eintrag.pop(attribute, None)     \n",
    "    return loaded_data\n",
    " \n",
    "def main():\n",
    "    input_filename = \"trainingData_with_propertyAge.json\"\n",
    "    output_filename = \"trainingData_with_city.json\"\n",
    "    \n",
    "    # Lade die Daten ein\n",
    "    loaded_data = load_data(input_filename)\n",
    "\n",
    "    # Handle special characters\n",
    "    loaded_data  = handle_special_chars_in_data(loaded_data)\n",
    "\n",
    "    # Umwandeln der Attribute\n",
    "    loaded_data = splitdata(loaded_data, ['bundesland', 'houseType'])\n",
    "    loaded_data = handle_datasplit(loaded_data)\n",
    "    \n",
    "    # Entfernen von Attributen\n",
    "    loaded_data = pop_Attribute(loaded_data, ['stadtteil', 'plz', 'strasse', '_class'])\n",
    "        \n",
    "    # Speichern der endgültigen Daten in eine JSON-Datei\n",
    "    save_to_json(loaded_data, output_filename)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lineare Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpyspark\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Trainingsdaten einlesen\n",
    "with open('short_data.json', 'r') as file:\n",
    "    training_data = json.load(file)\n",
    "\n",
    "# Trainingsdaten in separate Arrays konvertieren\n",
    "X_train = np.array([[data['roomCount'], data['propertyAge'], data['livingSpace'], data['hasBasement'],\n",
    "                     data['hasBalcony'], data['parkingLotCount'], data['hasGarden'], data['hasElevator'],\n",
    "                     data['houseType apartment'], data['houseType ground_floor'], data['houseType half_basement'],\n",
    "                     data['houseType roof_storey'], data['houseType maisonette'], data['houseType raised_ground_floor'],\n",
    "                     data['houseType terraced_flat'], data['houseType other'], data['houseType penthouse'],\n",
    "                     data['houseType loft'], data['bundesland Berlin'], data['bundesland Bremen'],\n",
    "                     data['bundesland Nordrhein Westfalen'], data['bundesland Hamburg'], data['bundesland Sachsen Anhalt'],\n",
    "                     data['bundesland Niedersachsen'], data['bundesland Baden Wuerttemberg'], data['bundesland Rheinland Pfalz'],\n",
    "                     data['bundesland Hessen'], data['bundesland Brandenburg'], data['bundesland Sachsen'],\n",
    "                     data['bundesland Thueringen'], data['bundesland Bayern'], data['bundesland Mecklenburg Vorpommern'],\n",
    "                     data['bundesland Schleswig Holstein'], data['bundesland Saarland'], data['city_avr_rating'],\n",
    "                     data['city_avr_acc_population_change'], data['city_avr_population_change_last_year'],\n",
    "                     data['city_avr_persons_per_km2'], data['closest_city_distance']]\n",
    "                    for data in training_data])\n",
    "y_train = np.array([data['rent'] for data in training_data])\n",
    "\n",
    "# Lineare Regression erstellen und trainieren\n",
    "regression = LinearRegression()\n",
    "regression.fit(X_train, y_train)\n",
    "\n",
    "# Testdaten einlesen\n",
    "with open('test_data.json', 'r') as file:\n",
    "    test_data = json.load(file)\n",
    "\n",
    "# Testdaten in separate Arrays konvertieren\n",
    "X_test = np.array([[data['roomCount'], data['propertyAge'], data['livingSpace'], data['hasBasement'],\n",
    "                    data['hasBalcony'], data['parkingLotCount'], data['hasGarden'], data['hasElevator'],\n",
    "                    data['houseType apartment'], data['houseType ground_floor'], data['houseType half_basement'],\n",
    "                    data['houseType roof_storey'], data['houseType maisonette'], data['houseType raised_ground_floor'],\n",
    "                    data['houseType terraced_flat'], data['houseType other'], data['houseType penthouse'],\n",
    "                    data['houseType loft'], data['bundesland Berlin'], data['bundesland Bremen'],\n",
    "                    data['bundesland Nordrhein Westfalen'], data['bundesland Hamburg'], data['bundesland Sachsen Anhalt'],\n",
    "                    data['bundesland Niedersachsen'], data['bundesland Baden Wuerttemberg'], data['bundesland Rheinland Pfalz'],\n",
    "                    data['bundesland Hessen'], data['bundesland Brandenburg'], data['bundesland Sachsen'],\n",
    "                    data['bundesland Thueringen'], data['bundesland Bayern'], data['bundesland Mecklenburg Vorpommern'],\n",
    "                    data['bundesland Schleswig Holstein'], data['bundesland Saarland'], data['city_avr_rating'],\n",
    "                    data['city_avr_acc_population_change'], data['city_avr_population_change_last_year'],\n",
    "                    data['city_avr_persons_per_km2'], data['closest_city_distance']]\n",
    "                   for data in test_data])\n",
    "\n",
    "# Vorhersagen für die Testdaten machen\n",
    "predictions = regression.predict(X_test)\n",
    "\n",
    "# Ausgabe der Vorhersagen\n",
    "for i, prediction in enumerate(predictions):\n",
    "    print(f\"Vorhersage für Datenpunkt {i+1}: {prediction}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
